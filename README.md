# Question Answering Models Implementation

This repository contains implementations of three different transformer-based models for Question Answering tasks using the SQuAD dataset.

## Models Implemented

### 1. AlBERTa Model
- Learning rate: 2e-6
- Batch size: 16
- Epochs: 10
- F1 Score: 0.168

### 2. BERT Model
- Learning rate: 2e-4
- Batch size: 16
- Epochs: 6
- F1 Score: 37.038

### 3. DistilBERT Model
- Learning rate: 2e-6
- Batch size: 16
- Epochs: 10
- F1 Score: 38.267

## Dataset

The models are trained and evaluated on the SQuAD (Stanford Question Answering Dataset) which consists of:
- Wikipedia articles
- Question-answer pairs
- Context paragraphs
- Answers that span within the context text

## Performance Evaluation
Models are evaluated using Exact Match and F1 Score metrics. 

## Author
Maitreyee Narkhede

